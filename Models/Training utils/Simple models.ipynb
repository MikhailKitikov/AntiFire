{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks.callbacks import ModelCheckpoint\n",
    "from keras.layers.pooling import AveragePooling2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Input, Convolution2D, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report \n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os   \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 15, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '../Datasets/Videos/lstm/train/'\n",
    "path_test = '../Datasets/Videos/lstm/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "y_train = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path_train):\n",
    "    if file.endswith(\".csv\"):\n",
    "        data = pd.read_csv(path_train + file).drop('Unnamed: 0', axis=1)\n",
    "        pos = 9\n",
    "        while pos < data.shape[0]:\n",
    "            X_train.append(data.drop('label', axis=1).values[pos-9: pos+1, :].flatten())\n",
    "            y_train.append(data['label'].iloc[pos])\n",
    "            pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path_test):\n",
    "    if file.endswith(\".csv\"):\n",
    "        data = pd.read_csv(path_test + file).drop('Unnamed: 0', axis=1)\n",
    "        pos = 9\n",
    "        while pos < data.shape[0]:\n",
    "            X_test.append(data.drop('label', axis=1).values[pos-9: pos+1, :].flatten())\n",
    "            y_test.append(data['label'].iloc[pos])\n",
    "            pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "def label_to_float(x):\n",
    "    return 0.0 if x == 'fire' else 1.0\n",
    "\n",
    "y_train = np.array([label_to_float(x) for x in y_train])\n",
    "y_test = np.array([label_to_float(x) for x in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.abs(X_train).max()\n",
    "\n",
    "X_train /= scale\n",
    "X_test /= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:   18.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=4, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(n_jobs=4, verbose=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7971014492753623\n",
      "Precision: 0.9678899082568807\n",
      "Recall: 0.8115384615384615\n",
      "F1: 0.8828451882845189\n",
      "ROC AUC: 0.6870192307692308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision:\", precision_score(y_test, pred, pos_label=0))\n",
    "print(\"Recall:\", recall_score(y_test, pred, pos_label=0))\n",
    "print(\"F1:\", f1_score(y_test, pred, pos_label=0))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
       "                       oob_score=False, random_state=None, verbose=1,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_jobs=4, verbose=1)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6956521739130435\n",
      "Precision: 0.9680851063829787\n",
      "Recall: 0.7\n",
      "F1: 0.8125\n",
      "ROC AUC: 0.6625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "pred = forest.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision:\", precision_score(y_test, pred, pos_label=0))\n",
    "print(\"Recall:\", recall_score(y_test, pred, pos_label=0))\n",
    "print(\"F1:\", f1_score(y_test, pred, pos_label=0))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(verbose=1)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.9540229885057471\n",
      "Recall: 0.9576923076923077\n",
      "F1: 0.9558541266794626\n",
      "ROC AUC: 0.6038461538461538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "pred = svc.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision:\", precision_score(y_test, pred, pos_label=0))\n",
    "print(\"Recall:\", recall_score(y_test, pred, pos_label=0))\n",
    "print(\"F1:\", f1_score(y_test, pred, pos_label=0))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
