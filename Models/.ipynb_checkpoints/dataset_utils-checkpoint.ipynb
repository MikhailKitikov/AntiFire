{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from imutils import paths\n",
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../Datasets/Images/Final/'\n",
    "imagePaths = list(paths.list_images(path_to_data))\n",
    "N_size = len(imagePaths)\n",
    "\n",
    "gt_info = pd.read_csv(path_to_data + 'labels.csv')\n",
    "data_list = []\n",
    "\n",
    "for i in range(N_size):\n",
    "    # load image\n",
    "    imagePath = imagePaths[i]\n",
    "    image = cv2.imread(imagePath)\n",
    "    data_list.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data_list)\n",
    "data_list.clear()\n",
    "labels = gt_info[['fire', 'smoke', 'normal']].values\n",
    "    \n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, \n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "valAug = ImageDataGenerator()\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk99/anaconda3/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 27s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the ResNet-50, disable head\n",
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False, \n",
    "                     input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_classes = 3\n",
    "\n",
    "# constructing new head (sigmoid for multi-label)\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(N_classes, activation=\"sigmoid\")(headModel)\n",
    "\n",
    "# combined model\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# freeze all base layers\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-4425ff1fd9e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / args[\"epochs\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINIT_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINIT_LR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# binary crossentropy - for multilabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS = 75\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "#opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / args[\"epochs\"])\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "# binary crossentropy - for multilabel\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit_generator(\n",
    "    trainAug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=valAug.flow(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] Completed successfully!\n"
     ]
    }
   ],
   "source": [
    "path_to_data = '../Datasets/Images/Mixed/3_5k/'\n",
    "\n",
    "gt_info = pd.read_csv(path_to_data + 'imagenames-classes.csv', header=None)\n",
    "gt_info.columns = pd.Series(['image_path', 'fire', 'smoke'])\n",
    "#img = Image.open(path_to_data + '10010466715.jpg')\n",
    "#img.show()\n",
    "#pix = np.array(img)\n",
    "#pix.shape\n",
    "#cv2.imshow('image', image)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(path_to_data))\n",
    "\n",
    "N_size = len(imagePaths)\n",
    "path_to_save = '../Datasets/Images/Final/'\n",
    "\n",
    "new_paths = []\n",
    "fire = []\n",
    "smoke = []\n",
    "normal = []\n",
    "\n",
    "for i in range(N_size):\n",
    "    \n",
    "    # load labels\n",
    "    is_fire = gt_info.loc[i, 'fire']\n",
    "    is_smoke = gt_info.loc[i].smoke\n",
    "    is_normal = int(is_fire == 0 and is_smoke == 0)\n",
    "    label = [is_fire, is_smoke, is_normal]\n",
    "\n",
    "    # load image\n",
    "    imagePath = imagePaths[i]\n",
    "    image = cv2.imread(imagePath)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    # save processed image\n",
    "    new_image_path = path_to_save + '{}.jpg'.format(i + 1)\n",
    "    cv2.imwrite(new_image_path, image)\n",
    "    \n",
    "    # update the data and labels lists, respectively\n",
    "    fire.append(is_fire)\n",
    "    smoke.append(is_smoke)\n",
    "    normal.append(is_normal)\n",
    "    new_paths.append(new_image_path)\n",
    "    \n",
    "\n",
    "proc_labels = pd.DataFrame({'path': new_paths, 'fire': fire, \n",
    "                            'smoke': smoke, 'normal': normal})\n",
    "proc_labels.to_csv(path_to_save + 'labels.csv')\n",
    "\n",
    "print('[INFO] Completed successfully!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
